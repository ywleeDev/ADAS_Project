import os
import cv2
import torch
import numpy as np
from ultralytics import YOLO
from torchmetrics.detection.mean_ap import MeanAveragePrecision
from tqdm import tqdm

# ==============================================================================
# ğŸ† [ìµœì¢… í•„ì‚´ê¸°] ë¶„ì•¼ë³„ ì „ë¬¸ê°€ ì±„ìš© (Class-wise Ensemble)
# ==============================================================================
# 1. ìë™ì°¨(0), ìì „ê±°(2) ë‹´ë‹¹: RT-DETR (ì „ì²´ 1ë“±)
MODEL_MAIN_PATH = 'ADAS_Project/models/rtdetr_best.pt'

# 2. ë³´í–‰ì(1) ë‹´ë‹¹: YOLOv11x (ê³ í•´ìƒë„ë¼ ì‘ì€ ì‚¬ëŒ ì˜ ì¡ìŒ)
# (ë§Œì•½ 11xê°€ ì—†ìœ¼ë©´ yolov11m_best.ptë¡œ ë°”ê¾¸ì„¸ìš”)
MODEL_SUB_PATH  = 'ADAS_Project/models/yolov11x_best.pt'

IMG_DIR = "datasets/kitti/images/val"
LBL_DIR = "datasets/kitti/labels/val"
# ==============================================================================

def load_yolo_label(label_path, img_w, img_h):
    boxes, labels = [], []
    if os.path.exists(label_path):
        with open(label_path, 'r') as f:
            for line in f:
                parts = list(map(float, line.strip().split()))
                cls = int(parts[0])
                x, y, w, h = parts[1], parts[2], parts[3], parts[4]
                x1 = (x - w/2) * img_w
                y1 = (y - h/2) * img_h
                x2 = (x + w/2) * img_w
                y2 = (y + h/2) * img_h
                boxes.append([x1, y1, x2, y2])
                labels.append(cls)
    return torch.tensor(boxes), torch.tensor(labels)

def run_class_wise_ensemble():
    print(f"ğŸš€ [Class-wise Ensemble] ì„ì§€ ì•Šê³  'ì˜í•˜ëŠ” ê²ƒ'ë§Œ ê³¨ë¼ ë‹´ê¸° ì‹œì‘...")
    
    if not os.path.exists(MODEL_MAIN_PATH) or not os.path.exists(MODEL_SUB_PATH):
        print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    model_main = YOLO(MODEL_MAIN_PATH)
    model_sub  = YOLO(MODEL_SUB_PATH)
    
    metric = MeanAveragePrecision(iou_type="bbox", class_metrics=True)
    img_files = [f for f in os.listdir(IMG_DIR) if f.endswith('.png')]
    
    print(f"\nğŸ“Š ì´ {len(img_files)}ì¥ ì •ë°€ ë¶„ì„ ì¤‘...")

    for img_file in tqdm(img_files):
        img_path = os.path.join(IMG_DIR, img_file)
        lbl_path = os.path.join(LBL_DIR, img_file.replace('.png', '.txt'))
        img = cv2.imread(img_path)
        if img is None: continue
        h, w, _ = img.shape
        
        # ê°ì ì¶”ë¡  (TTA ë„ê³  ìˆœì • ì‹¤ë ¥ìœ¼ë¡œ)
        res_main = model_main.predict(img, verbose=False, augment=False)[0]
        res_sub  = model_sub.predict(img, verbose=False, augment=False)[0]

        final_boxes = []
        final_scores = []
        final_labels = []

        # [ì „ëµ í•µì‹¬] í—¤ì³ ëª¨ì—¬!
        
        # 1. RT-DETRì—ì„œëŠ” 'ì°¨(0)'ì™€ 'ìì „ê±°(2)'ë§Œ ê°€ì ¸ì˜´
        if len(res_main.boxes) > 0:
            for box, score, cls in zip(res_main.boxes.xyxy, res_main.boxes.conf, res_main.boxes.cls):
                cls_id = int(cls.item())
                if cls_id in [0, 2]: # Car, Cyclist
                    final_boxes.append(box.cpu().numpy())
                    final_scores.append(score.item())
                    final_labels.append(cls_id)

        # 2. YOLOv11xì—ì„œëŠ” 'ë³´í–‰ì(1)'ë§Œ ê°€ì ¸ì˜´
        if len(res_sub.boxes) > 0:
            for box, score, cls in zip(res_sub.boxes.xyxy, res_sub.boxes.conf, res_sub.boxes.cls):
                cls_id = int(cls.item())
                if cls_id == 1: # Pedestrian
                    final_boxes.append(box.cpu().numpy())
                    final_scores.append(score.item())
                    final_labels.append(cls_id)

        # ì±„ì  ë“±ë¡
        preds = []
        if len(final_boxes) > 0:
            preds = [dict(
                boxes=torch.tensor(np.array(final_boxes)), 
                scores=torch.tensor(np.array(final_scores)), 
                labels=torch.tensor(np.array(final_labels)).int()
            )]
        else:
            preds = [dict(boxes=torch.tensor([]), scores=torch.tensor([]), labels=torch.tensor([]))]

        t_boxes, t_labels = load_yolo_label(lbl_path, w, h)
        target = [dict(boxes=t_boxes, labels=t_labels.int())]
        metric.update(preds, target)

    print("\nğŸ§® ìµœì¢… ì„±ì  ì‚°ì¶œ ì¤‘...")
    result = metric.compute()
    
    print("\n" + "="*50)
    print("      ğŸ† ë¶„ì•¼ë³„ ì „ë¬¸ê°€(Class-wise) ìµœì¢… ì„±ì  ğŸ†")
    print("="*50)
    print(f"â–¶ ì¢…í•© mAP 0.50  : {result['map_50'].item():.4f}")
    print(f"â–¶ ì •ë°€ mAP 50-95 : {result['map'].item():.4f}")
    print("-" * 50)
    
    if 'map_50_per_class' in result:
        classes = ['Car', 'Pedestrian', 'Cyclist']
        scores = result['map_50_per_class']
        print("[í´ë˜ìŠ¤ë³„ mAP 50]")
        for i, cls in enumerate(classes):
            if i < len(scores):
                print(f"  - {cls:<10} : {scores[i].item():.4f}")
    print("="*50)

if __name__ == "__main__":
    run_class_wise_ensemble()
